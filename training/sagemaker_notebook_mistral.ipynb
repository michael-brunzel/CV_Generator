{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::211125449279:role/service-role/AmazonSageMaker-ExecutionRole-20240307T175168\n",
      "sagemaker bucket: sagemaker-eu-west-1-211125449279\n",
      "sagemaker session region: eu-west-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and store the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "# dataset used\n",
    "data_path = 'MichaelAI23/English_CVs'\n",
    "\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'samples/datasets/English_CVs'\n",
    "\n",
    "cutoff_len = 1024 # 512\n",
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "use_special_token = True\n",
    "\n",
    "if use_special_token:\n",
    "    # Add the single quote as special token for faster inference (only fill the blanks --> no embedding training necessary, since token exists already)\n",
    "    tokenizer.add_tokens([\"\\'\"], special_tokens=True) #, \"}, \"])\n",
    "\n",
    "    assert len(tokenizer) == 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = {\n",
    "    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\nInstruction:\\n{instruction}\\n\\nInput:\\n{input}\\n\\nResponse:\\n\",\n",
    "    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\nInstruction:\\n{instruction}\\n\\nResponse:\\n\",\n",
    "    \"response_split\": \"Response:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(\n",
    "    template: str,\n",
    "    instruction: str,\n",
    "    input: Union[None, str] = None,\n",
    "    label: Union[None, str] = None,\n",
    ") -> str:\n",
    "    # returns the full prompt from instruction and optional input\n",
    "    # if a label (=response, =output) is provided, it's also appended.\n",
    "    if label:\n",
    "        res = template[\"prompt_input\"].format(\n",
    "            instruction=instruction, input=input\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": res},\n",
    "            {\"role\": \"assistant\", \"content\": f\" {label}\"}\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        res = template[\"prompt_input\"].format(\n",
    "            instruction=instruction, input=input\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": res},\n",
    "        ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def tokenize(messages):\n",
    "    # Create the final prompt (with the template and tokenize it)\n",
    "    final_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    result = tokenizer(\n",
    "        final_prompt,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False, # this is already done by the application of the chat template\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    result[\"full_prompt\"] = final_prompt\n",
    "\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(\n",
    "        template,\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"],\n",
    "    )\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'hobbies', 'personal', 'work_experience', 'skills', 'academia', 'education', 'overall'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(data_path)\n",
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benjamin Costa is a guest at The Taj Exotica Resort & Spa in the Maldives. He can be reached via email at bencosta@example.com. His address is Villa 12, Oceanfront Drive, South Male Atoll, Maldives. For any inquiries or reservations, you can contact him at +960-123-4567.\\nI enjoy swimming as a hobby, as it allows me to relax and stay active outside of my work as a Data Scientist. In addition, I also love hiking in the mountains and playing the guitar in my free time.\\nData Scientist, 2014 - 2016 at Google\\n- Developed machine learning models to optimize search algorithms.\\n- Conducted data analysis and visualization to extract actionable insights from large datasets.\\n- Collaborated with cross-functional teams to implement data-driven solutions for product enhancements.\\n- Presented findings to stakeholders and provided recommendations for business strategies.\\n\\nSenior Data Scientist, 2012 - 2014 at Amazon\\n- Led a team of data scientists in developing predictive analytics models for customer behavior forecasting.\\n- Implemented scalable data pipelines using cloud-based technologies for real-time data processing.\\n- Worked closely with product managers to define key performance indicators and measure the impact of data-driven initiatives.\\n- Mentored junior data scientists and conducted training sessions on advanced analytical techniques.\\n- Master of Science in Data Science, Politecnico di Milano, 2012\\n- Bachelor of Science in Computer Science, UniversitÃ  degli Studi di Milano, 2009\\nProficient in statistical analysis and data visualization techniques, with a strong background in machine learning algorithms. Skilled at deriving actionable insights from complex datasets to drive informed decision-making and business growth.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"] = data[\"train\"].add_column(\n",
    "    \"instruction\",\n",
    "    [\"Extract the start and end sequences for the categories 'personal information', 'work experience', 'education' and 'skills' from the following text in dictionary form\"]*len(data[\"train\"])\n",
    ")\n",
    "\n",
    "data[\"train\"] = data[\"train\"].rename_column(\"overall\", \"input\")\n",
    "data[\"train\"][\"input\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_set_size= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if val_set_size > 0:\n",
    "    train_val = data[\"train\"].train_test_split(\n",
    "        test_size=val_set_size, shuffle=True, seed=42\n",
    "    )\n",
    "    train_data = (\n",
    "        train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    "    )\n",
    "    val_data = (\n",
    "        train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    "    )\n",
    "else:\n",
    "    train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    val_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'hobbies', 'personal', 'work_experience', 'skills', 'academia', 'education', 'input', 'instruction', 'input_ids', 'attention_mask', 'full_prompt', 'labels'],\n",
       "    num_rows: 900\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- I enjoy playing golf in my free time and often participate in local tournaments.\\n- Photography is another passion of mine, capturing beautiful moments and landscapes brings me joy.\\n- Cooking is a relaxing hobby for me, experimenting with new recipes and flavors is always exciting.\\n- I love hiking and exploring nature trails on the weekends, it helps me unwind and stay active.\\n- Reading fiction novels is a favorite pastime of mine, getting lost in a good book is a great escape from reality.\\n\\nAs a seasoned Business Analyst, I excel in translating complex business requirements into actionable insights that drive strategic decision-making. With a keen eye for detail and a knack for data analysis, I have a proven track record of delivering innovative solutions to enhance operational efficiency and maximize profitability. My strong communication skills enable me to effectively collaborate with cross-functional teams and stakeholders to achieve project objectives seamlessly.\\n\\n- Bachelor of Business Administration, University of Melbourne, 2017\\n- Master of Business Analytics, Monash University, 2020\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[\"input\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:31:42.466838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 16:31:42.466996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 16:31:42.468254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-21 16:31:42.478998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-21 16:31:43.879026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<s> [INST] Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\nInstruction:\\nExtract the start and end sequences for the categories ' personal information' , ' work experience' , ' education'  and ' skills'  from the following text in dictionary form\\n\\nInput:\\n\\nProficient in statistical analysis and data visualization techniques, with a strong background in machine learning algorithms. Skilled at deriving actionable insights from complex datasets to drive informed decision-making and business growth.\\n- I enjoy dancing salsa and bachata in my free time.\\n- I am an avid hiker and love exploring new trails in the mountains.\\n- Painting is a relaxing hobby of mine, and I often create abstract art pieces.\\n- Cooking is another passion of mine, and I love experimenting with different cuisines.\\n- I have a green thumb and enjoy gardening, especially growing herbs and vegetables.\\n- Reading fiction novels is a favorite pastime of mine, and I always have a book on hand.\\nData Scientist, 2019 - Present at Amazon\\n- Conducted advanced data analysis to optimize customer segmentation strategies.\\n- Developed machine learning models to predict sales trends and improve inventory management.\\n\\nJunior Data Scientist, 2017 - 2019 at Google\\n- Collaborated with cross-functional teams to design and implement data-driven solutions for ad targeting.\\n- Utilized natural language processing techniques to enhance search engine algorithms and improve user experience.\\n- Mail: harper.andrade@ritzcarlton.com\\n- Address: The Ritz-Carlton, Amelia Island, 4750 Amelia Island Pkwy, Fernandina Beach, FL 32034, USA\\n- Phone: +1 (904) 277-1100\\n- Name: Harper Andrade\\n- LinkedIn: linkedin.com/in/harper-andrade\\n\\nResponse:\\n [/INST] {' pe' : {' s' : ' - Mail' , ' e' : ' -andrade' }, ' ed' : {' s' : '' , ' e' : '' }, ' wo' : {' s' : ' Data' , ' e' : '  experience.' }, ' sk' : {' s' : ' Proficient' , ' e' : '  growth.' }}</s>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data[\"input_ids\"][2]) #[:len(train_data[\"input_ids\"][2]) - 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"input_ids\"][2][:len(train_data[\"input_ids\"][2]) - 63][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.map(lambda example: {\"token_len\": len(example[\"input_ids\"])})\n",
    "val_data = val_data.map(lambda example: {\"token_len\": len(example[\"input_ids\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_data[\"token_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if max(train_data[\"token_len\"]) > cutoff_len or max(val_data[\"token_len\"]) > cutoff_len:\n",
    "    raise ValueError(\"You have samples that are longer than your cutoff length. This can lead to unintended side consequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "train_data.save_to_disk(training_input_path)\n",
    "\n",
    "# save test_dataset to s3\n",
    "val_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/val'\n",
    "val_data.save_to_disk(val_input_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning & starting Sagemaker Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "time_string = time.strftime(\"%H-%M-%S\")\n",
    "\n",
    "base_job_name=f\"LLM-Textmarker-{base_model}-{time_string}\"\n",
    "base_job_name = re.sub(r\"[_/\\.]\", \"-\", base_job_name)\n",
    "checkpoint_in_bucket=\"checkpoints\"\n",
    "\n",
    "# The S3 URI to store the checkpoints\n",
    "checkpoint_s3_bucket=\"s3://{}/{}/{}\".format(sess.default_bucket(), base_job_name, checkpoint_in_bucket)\n",
    "\n",
    "# The local path where the model will save its checkpoints in the training container\n",
    "checkpoint_local_path=\"/opt/ml/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'epochs': 5,\n",
    "    # 'batch_size': 8,\n",
    "    'batch_size': 1,\n",
    "    'base_model': base_model,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'num_epochs': 5,\n",
    "    'learning_rate': 3e-4,\n",
    "    'cutoff_len': cutoff_len,\n",
    "    'lora_r': 8,\n",
    "    'lora_alpha': 16,\n",
    "    'lora_dropout': 0.05,\n",
    "    'group_by_length': False,\n",
    "    'device_map': 'auto',\n",
    "    'model_dir': checkpoint_local_path,\n",
    "    'use_special_token': use_special_token\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(entry_point='train_mistral.py',\n",
    "                            source_dir='./scripts',\n",
    "                            instance_type='ml.g5.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            base_job_name=base_job_name,\n",
    "                            role=role,\n",
    "                            transformers_version='4.36',\n",
    "                            pytorch_version='2.1',\n",
    "                            py_version='py310',\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            # Parameters required to enable checkpointing\n",
    "                            checkpoint_s3_uri=checkpoint_s3_bucket,\n",
    "                            checkpoint_local_path=checkpoint_local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': training_input_path, 'val': val_input_path}, job_name=base_job_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tar the model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-west-1-211125449279/LLM-Textmarker-mistralai-Mistral-7B-Instruct-v0-2-15-24-12/checkpoints/model_files/adapter_config.json to model/adapter_config.json\n",
      "download: s3://sagemaker-eu-west-1-211125449279/LLM-Textmarker-mistralai-Mistral-7B-Instruct-v0-2-15-24-12/checkpoints/model_files/adapter_model.safetensors to model/adapter_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://sagemaker-eu-west-1-211125449279/LLM-Textmarker-mistralai-Mistral-7B-Instruct-v0-2-15-24-12/checkpoints/model_files ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar zcvf model.tar.gz ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz s3://sagemaker-eu-west-1-211125449279/LLM-Textmarker-mistralai-Mistral-7B-Instruct-v0-2-15-24-12/checkpoints/model_files/model.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Deploying the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = huggingface_estimator.deploy(1, \"ml.g4dn.2xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_model()\n",
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
